{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import re\n",
    "from tqdm import tqdm_notebook\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "df_final = pd.read_csv('coursera.csv').drop('Unnamed: 0',axis=1)\n",
    "df_stack = pd.read_csv('tidy_questions.csv').drop('Unnamed: 0', axis=1).set_index('Id').dropna()\n",
    "\n",
    "df_final['level'] = df_final['level'].fillna('unknown')\n",
    "\n",
    "df_final['Text'] = df_final[\"about\"] + df_final[\"syllabus\"]\n",
    "df_final['index'] = df_final['index'] + ' ' + df_final['level'] + ' ' + df_final['rating'].astype('str') + ' ' + df_final['rating_count'].astype('str')\n",
    "df_train = df_final[[\"index\", \"Text\"]]\n",
    "\n",
    "df_train.set_index('index', drop = True, inplace=True)\n",
    "\n",
    "df_cnn = pd.concat([df_train, df_stack], axis=0)\n",
    "\n",
    "#Define the TFIDF vectorizer that will be used to process the data\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df_cnn['Text'])\n",
    "tfidf_courses = tfidf_vectorizer.transform(df_train['Text'])\n",
    "tfidf_questions = tfidf_vectorizer.transform(df_stack['Text'])\n",
    "\n",
    "nbrs1 = NearestNeighbors(n_neighbors=533).fit(tfidf_matrix)\n",
    "nbrs_courses1 = NearestNeighbors(n_neighbors=533).fit(tfidf_courses)\n",
    "nbrs_questions1 = NearestNeighbors(n_neighbors=533).fit(tfidf_questions)\n",
    "\n",
    "def get_closest_neighs1(name, target='course'):\n",
    "    if target == 'course':\n",
    "        nbrs_local1 = nbrs_courses1\n",
    "    elif target == 'question':\n",
    "        nbrs_local1 = nbrs_questions1\n",
    "    elif target == 'multi':\n",
    "        nbrs_local1 = nbrs1\n",
    "    row = df_cnn.index.get_loc(name)\n",
    "    distances, indices = nbrs_local1.kneighbors(tfidf_matrix.getrow(row))\n",
    "    indexes_similar = pd.Series(indices.flatten()).map(df_cnn.reset_index()['index'])\n",
    "    result = pd.DataFrame({'distance': distances.flatten(), 'index': indexes_similar})\n",
    "    \n",
    "    return result\n",
    "\n",
    "#pred1 = get_closest_neighs(id_q, target='course')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2717: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2717: DtypeWarning: Columns (3,18,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_qu = pd.read_csv('coursera_ques.csv')\n",
    "posts = pd.read_csv(\"Posts.csv\",  encoding = \"ISO-8859-1\").dropna(subset=['Tags'])[['Id', 'Tags']].values\n",
    "\n",
    "df_qu.tail()\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "idx = 533\n",
    "\n",
    "courses = df_qu.values[:idx,:]\n",
    "questions = df_qu.values[idx:, :]\n",
    "\n",
    "questions[:,0]\n",
    "\n",
    "tags_df = pd.read_csv('Tags.csv',  encoding = \"ISO-8859-1\" )\n",
    "tags = tags_df.sort_values('Count', ascending=False)['TagName'].values[:500]\n",
    "\n",
    "questions.shape\n",
    "\n",
    "tags.shape\n",
    "\n",
    "tags_indexes = dict([(tag, index) for index, tag in enumerate(tags)])\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "array = np.zeros((courses.shape[0],tags.shape[0]*2) , dtype=np.int8)\n",
    "for i in range(courses.shape[0]):\n",
    "    for j in range(tags.shape[0]):\n",
    "        if tags[j] in courses[i, 1]:\n",
    "            array[i, tags_indexes[tags[j]]] = 1\n",
    "            array[i, tags_indexes[tags[j]] + tags.shape[0]] = 1\n",
    "\n",
    "courses_df = pd.DataFrame(array)\n",
    "courses_df['id'] = courses[:,0]\n",
    "courses_df.set_index('id',inplace=True)\n",
    "\n",
    "array1 = np.zeros((questions.shape[0],tags.shape[0]*2) , dtype=np.int8)\n",
    "for i in range(questions.shape[0]):\n",
    "    for j in range(tags.shape[0]):\n",
    "        if tags[j] in questions[i, 1]:\n",
    "            array1[i, tags_indexes[tags[j]]] = 1\n",
    "        if tags[j] in posts[i, 1]:\n",
    "            array1[i, tags_indexes[tags[j]] + tags.shape[0]] = 1\n",
    "\n",
    "questions_df = pd.DataFrame(array1)\n",
    "questions_df['id'] = questions[:,0]\n",
    "questions_df.set_index('id',inplace=True)\n",
    "\n",
    "union = csr_matrix(pd.concat([courses_df, questions_df],axis=0))\n",
    "questions_df = csr_matrix(questions_df)\n",
    "courses_df = csr_matrix(courses_df)\n",
    "\n",
    "tags = None\n",
    "tags_indexes = None\n",
    "array = None\n",
    "array1 = None\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "nbrs2 = NearestNeighbors(n_neighbors=533).fit(union)\n",
    "nbrs_courses2 = NearestNeighbors(n_neighbors=533).fit(courses_df)\n",
    "nbrs_questions2 = NearestNeighbors(n_neighbors=533).fit(questions_df)\n",
    "\n",
    "df_qu = df_qu.set_index('Unnamed: 0')\n",
    "\n",
    "def get_closest_neighs2(name, target='course'):\n",
    "    if target == 'course':\n",
    "        nbrs_local2 = nbrs_courses2\n",
    "    elif target == 'question':\n",
    "        nbrs_local2 = nbrs_questions2\n",
    "    elif target == 'multi':\n",
    "        nbrs_local2 = nbrs2\n",
    "    row = df_qu.index.get_loc(name)\n",
    "    distances, indices = nbrs_local2.kneighbors(union.getrow(row))\n",
    "    indexes_similar = pd.Series(indices.flatten()).map(df_qu.reset_index()['Unnamed: 0'])\n",
    "    result = pd.DataFrame({'distance': distances.flatten(), 'index': indexes_similar})\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting random\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id got\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-12-03 13:34:56,580 - telegram.ext.dispatcher - ERROR - An uncaught error was raised while processing the update\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\indexes\\base.py\", line 2134, in get_loc\n",
      "    return self._engine.get_loc(key)\n",
      "  File \"pandas\\index.pyx\", line 132, in pandas.index.IndexEngine.get_loc (pandas\\index.c:4433)\n",
      "  File \"pandas\\index.pyx\", line 154, in pandas.index.IndexEngine.get_loc (pandas\\index.c:4279)\n",
      "  File \"pandas\\src\\hashtable_class_helper.pxi\", line 732, in pandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:13742)\n",
      "  File \"pandas\\src\\hashtable_class_helper.pxi\", line 740, in pandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:13696)\n",
      "KeyError: 'https:'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\telegram\\ext\\dispatcher.py\", line 270, in process_update\n",
      "    handler.handle_update(update, self)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\telegram\\ext\\commandhandler.py\", line 171, in handle_update\n",
      "    return self.callback(dispatcher.bot, update, **optional_args)\n",
      "  File \"<ipython-input-23-81996e0dea5d>\", line 68, in random_links\n",
      "    cour = c_link_by_qid(res)\n",
      "  File \"<ipython-input-23-81996e0dea5d>\", line 18, in c_link_by_qid\n",
      "    link = get_real_lol(qid)\n",
      "  File \"<ipython-input-25-0af4d8c6546c>\", line 4, in get_real_lol\n",
      "    tmpget2 = get_closest_neighs2(str(id))\n",
      "  File \"<ipython-input-2-65ab1e82076b>\", line 76, in get_closest_neighs2\n",
      "    row = df_qu.index.get_loc(name)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\indexes\\base.py\", line 2136, in get_loc\n",
      "    return self._engine.get_loc(self._maybe_cast_indexer(key))\n",
      "  File \"pandas\\index.pyx\", line 132, in pandas.index.IndexEngine.get_loc (pandas\\index.c:4433)\n",
      "  File \"pandas\\index.pyx\", line 154, in pandas.index.IndexEngine.get_loc (pandas\\index.c:4279)\n",
      "  File \"pandas\\src\\hashtable_class_helper.pxi\", line 732, in pandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:13742)\n",
      "  File \"pandas\\src\\hashtable_class_helper.pxi\", line 740, in pandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:13696)\n",
      "KeyError: 'https:'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def get_real_lol(id):\n",
    "    tmpget2 = get_closest_neighs2(str(id))\n",
    "    tmpget1 = get_closest_neighs1(int(id))\n",
    "    sscaler = StandardScaler()\n",
    "\n",
    "    data1 = tmpget1.set_index('index')\n",
    "    data2 = tmpget2.set_index('index')\n",
    "    data1['distance'] = sscaler.fit_transform(data1['distance'].values)\n",
    "    data2['distance'] = sscaler.fit_transform(data2['distance'].values)\n",
    "    data1['sum'] = data1['distance'] + data2['distance']\n",
    "    data1 = data1.sort_values('sum')\n",
    "    datatmp = data1.index[:3]\n",
    "    res = \"\"\n",
    "    for i in datatmp:\n",
    "        res += i.split(\" \")[0] + '\\n'\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "debug_tmp = \"\"\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "def get_qid(solink):\n",
    "    return solink.split(\"/\")[4]\n",
    "pref = \"data/NLP_dataset_final/\"\n",
    "\n",
    "courses_links_csv = pref + \"courses_links\" + debug_tmp + \".csv\"\n",
    "\n",
    "courses_links_csv = 'coursera_ques.csv'\n",
    "\n",
    "\n",
    "\n",
    "def c_link_by_qid(solink):\n",
    "    link = \"\"\n",
    "    link = get_real_lol(solink)\n",
    "    if (link == \"\"):\n",
    "        return \"Not found\"\n",
    "    return link.strip()\n",
    "\n",
    "def get_random_id():\n",
    "    num_lines = sum(1 for line in open(courses_links_csv))\n",
    "    r = random.randrange(600, num_lines)\n",
    "    for i, line in enumerate(open(courses_links_csv)):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        if i == r:\n",
    "            lnk = line.split(\" \")[0].split(',')[0]\n",
    "            return lnk\n",
    "    return \"Can not calculate\"\n",
    "    \n",
    "\n",
    "from telegram.ext import Updater\n",
    "updater = Updater(token='473606748:AAEQecsSQ3Xk6Cwl-yBgTcV1juIV0Fj5mCY')\n",
    "def start(bot, update):\n",
    "    res = \"examples\\n\"\n",
    "    with open(courses_links_csv) as courses_links_df:\n",
    "        count = 0\n",
    "        for line in courses_links_df.readlines():\n",
    "            count += 1\n",
    "            if (count < 600):\n",
    "                continue\n",
    "            if count > 605:\n",
    "                break\n",
    "            print(line)\n",
    "            qid = line.split(\",\")[0]\n",
    "            res += \"https://stackoverflow.com/questions/\" + qid + '\\n'\n",
    "    bot.send_message(chat_id=update.message.chat_id, text=res)\n",
    "dispatcher = updater.dispatcher\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "                level=logging.INFO)\n",
    "from telegram.ext import CommandHandler\n",
    "start_handler = CommandHandler('start', start)\n",
    "dispatcher.add_handler(start_handler)\n",
    "\n",
    "def echo(bot, update):\n",
    "    \n",
    "    qid = get_qid(update.message.text)\n",
    "    bot.send_message(chat_id=update.message.chat_id, text=c_link_by_qid(qid))\n",
    "    \n",
    "def random_links(bot, update):\n",
    "    print('getting random')\n",
    "    rid = get_random_id()\n",
    "    print(rid)\n",
    "    print('id got')\n",
    "    print('random got')\n",
    "    stov = \"https://stackoverflow.com/questions/\" + rid + '\\n'\n",
    "    bot.send_message(chat_id=update.message.chat_id, text=c_link_by_qid(rid))\n",
    "    bot.send_message(chat_id=update.message.chat_id, text=stov)\n",
    "    \n",
    "start_handler = CommandHandler('random', random_links)\n",
    "dispatcher.add_handler(start_handler)\n",
    "\n",
    "from telegram.ext import MessageHandler, Filters\n",
    "echo_handler = MessageHandler(Filters.text, echo)\n",
    "dispatcher.add_handler(echo_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "updater.start_polling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "updater.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
